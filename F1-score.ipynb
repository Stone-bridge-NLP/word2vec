{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import string\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Song</th>\n",
       "      <th>Song year</th>\n",
       "      <th>Artist</th>\n",
       "      <th>Genre</th>\n",
       "      <th>Lyrics</th>\n",
       "      <th>Track_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>craftsmanship</td>\n",
       "      <td>2005</td>\n",
       "      <td>buck-65</td>\n",
       "      <td>Hip-Hop</td>\n",
       "      <td>Most folks spend their days daydreaming of fin...</td>\n",
       "      <td>8294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>come-on-out</td>\n",
       "      <td>2012</td>\n",
       "      <td>the-elwins</td>\n",
       "      <td>Indie</td>\n",
       "      <td>Take your cold hands and put them on my face\\n...</td>\n",
       "      <td>21621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>riot</td>\n",
       "      <td>2013</td>\n",
       "      <td>bullet-for-my-valentine</td>\n",
       "      <td>Metal</td>\n",
       "      <td>Are you ready it's time for war\\nWe'll break d...</td>\n",
       "      <td>3301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>that-s-what-girls-do</td>\n",
       "      <td>2007</td>\n",
       "      <td>dream-street</td>\n",
       "      <td>Pop</td>\n",
       "      <td>You ask me why I change the color of my hair\\n...</td>\n",
       "      <td>2773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>believe-in-a-dollar</td>\n",
       "      <td>2012</td>\n",
       "      <td>cassidy</td>\n",
       "      <td>Hip-Hop</td>\n",
       "      <td>Do you believe in magic in a young girl's hear...</td>\n",
       "      <td>16797</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Song  Song year                   Artist    Genre  \\\n",
       "0         craftsmanship       2005                  buck-65  Hip-Hop   \n",
       "1           come-on-out       2012               the-elwins    Indie   \n",
       "2                  riot       2013  bullet-for-my-valentine    Metal   \n",
       "3  that-s-what-girls-do       2007             dream-street      Pop   \n",
       "4   believe-in-a-dollar       2012                  cassidy  Hip-Hop   \n",
       "\n",
       "                                              Lyrics  Track_id  \n",
       "0  Most folks spend their days daydreaming of fin...      8294  \n",
       "1  Take your cold hands and put them on my face\\n...     21621  \n",
       "2  Are you ready it's time for war\\nWe'll break d...      3301  \n",
       "3  You ask me why I change the color of my hair\\n...      2773  \n",
       "4  Do you believe in magic in a young girl's hear...     16797  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import tqdm\n",
    "\n",
    "df = pd.read_csv('./test.csv')\n",
    "\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "\n",
    "# Preprocessing\n",
    "def prepocessing(lyrics, remove_stopwords=False, stops=set(stopwords.words('english'))):\n",
    "    lyric_text = BeautifulSoup(lyric, \"html5lib\").get_text()\n",
    "    lyric_text = re.sub(\"[^a-zA-Z]\", \" \", lyric_text)\n",
    "    lyric_text = lyric_text.lower()\n",
    "    \n",
    "    lyric_words = lyric_text.split()\n",
    "    if remove_stopwords:\n",
    "        lyric_words = lyric_text.split()\n",
    "        lyric_words = [w for w in lyric_words if not w in stops]\n",
    "        \n",
    "    lyric_text = ' '.join(lyric_words)\n",
    "    return lyric_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 7935/7935 [00:03<00:00, 2403.82it/s]\n"
     ]
    }
   ],
   "source": [
    "processed_lyrics = []\n",
    "for lyric in tqdm.tqdm(df['Lyrics'].values):\n",
    "    processed = prepocessing(lyric)\n",
    "    processed_lyrics.append(processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_code = {\n",
    "    'Rock': 0,\n",
    "    'Metal': 1,\n",
    "    'Pop': 2,\n",
    "    'Indie': 3,\n",
    "    'Folk': 4,\n",
    "    'Electronic': 5,\n",
    "    'R&B': 6,\n",
    "    'Jazz': 7,\n",
    "    'Hip-Hop': 8,\n",
    "    'Country': 9,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "y = []\n",
    "for genre in df['Genre']:\n",
    "    y.append(class_code[genre])\n",
    "\n",
    "x = processed_lyrics\n",
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get F-1 Score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 1\n",
    "- embedding dim = 128\n",
    "- one bidirection layer\n",
    "- weak class weight (softmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model('./experiment1-LSTM64', custom_objects={'LSTMCell': tf.keras.layers.LSTM})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "248/248 [==============================] - 240s 963ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.26      0.30      0.27      1410\n",
      "           1       0.04      0.25      0.07       810\n",
      "           2       0.06      0.04      0.05      1110\n",
      "           3       0.05      0.02      0.03       510\n",
      "           4       0.19      0.08      0.12       495\n",
      "           5       0.00      0.00      0.00       660\n",
      "           6       0.00      0.00      0.00       510\n",
      "           7       0.06      0.00      0.01       660\n",
      "           8       0.00      0.00      0.00       960\n",
      "           9       0.00      0.00      0.00       810\n",
      "\n",
      "    accuracy                           0.09      7935\n",
      "   macro avg       0.07      0.07      0.05      7935\n",
      "weighted avg       0.08      0.09      0.07      7935\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ltw97\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\ltw97\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\ltw97\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "y_pred = model.predict(x, batch_size=32, verbose=1)\n",
    "y_pred_bool = np.argmax(y_pred, axis=1)\n",
    "\n",
    "print(classification_report(y, y_pred_bool))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 2\n",
    "- embedding dim = 300\n",
    "- one Bidirectional\n",
    "- weak class weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model('./experiment2-LSTM64', custom_objects={'LSTMCell': tf.keras.layers.LSTM})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "248/248 [==============================] - 235s 944ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.26      0.45      0.33      1410\n",
      "           1       0.04      0.16      0.06       810\n",
      "           2       0.05      0.04      0.04      1110\n",
      "           3       0.04      0.02      0.03       510\n",
      "           4       0.20      0.24      0.22       495\n",
      "           5       0.00      0.00      0.00       660\n",
      "           6       0.00      0.00      0.00       510\n",
      "           7       0.03      0.00      0.01       660\n",
      "           8       0.00      0.00      0.00       960\n",
      "           9       0.00      0.00      0.00       810\n",
      "\n",
      "    accuracy                           0.12      7935\n",
      "   macro avg       0.06      0.09      0.07      7935\n",
      "weighted avg       0.07      0.12      0.09      7935\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ltw97\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\ltw97\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\ltw97\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "y_pred = model.predict(x, batch_size=32, verbose=1)\n",
    "y_pred_bool = np.argmax(y_pred, axis=1)\n",
    "\n",
    "print(classification_report(y, y_pred_bool))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 2-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model('./experiment2-2bidriection', custom_objects={'LSTMCell': tf.keras.layers.LSTM})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "248/248 [==============================] - 505s 2s/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.24      0.38      0.30      1410\n",
      "           1       0.03      0.20      0.06       810\n",
      "           2       0.04      0.03      0.03      1110\n",
      "           3       0.04      0.02      0.02       510\n",
      "           4       0.16      0.06      0.09       495\n",
      "           5       0.00      0.00      0.00       660\n",
      "           6       0.00      0.00      0.00       510\n",
      "           7       0.00      0.00      0.00       660\n",
      "           8       0.00      0.00      0.00       960\n",
      "           9       0.00      0.00      0.00       810\n",
      "\n",
      "    accuracy                           0.10      7935\n",
      "   macro avg       0.05      0.07      0.05      7935\n",
      "weighted avg       0.06      0.10      0.07      7935\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ltw97\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\ltw97\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\ltw97\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "y_pred = model.predict(x, batch_size=32, verbose=1)\n",
    "y_pred_bool = np.argmax(y_pred, axis=1)\n",
    "\n",
    "print(classification_report(y, y_pred_bool))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 2-2-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model('./exp2-2-1', custom_objects={'LSTMCell': tf.keras.layers.LSTM})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "248/248 [==============================] - 244s 980ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00      1410\n",
      "           1       0.11      0.54      0.19       810\n",
      "           2       0.00      0.00      0.00      1110\n",
      "           3       0.05      0.04      0.04       510\n",
      "           4       0.13      0.48      0.20       495\n",
      "           5       0.10      0.16      0.12       660\n",
      "           6       0.00      0.00      0.00       510\n",
      "           7       0.11      0.00      0.00       660\n",
      "           8       0.03      0.02      0.03       960\n",
      "           9       0.80      0.00      0.01       810\n",
      "\n",
      "    accuracy                           0.10      7935\n",
      "   macro avg       0.13      0.12      0.06      7935\n",
      "weighted avg       0.13      0.10      0.05      7935\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ltw97\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\ltw97\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\ltw97\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "y_pred = model.predict(x, batch_size=32, verbose=1)\n",
    "y_pred_bool = np.argmax(y_pred, axis=1)\n",
    "\n",
    "print(classification_report(y, y_pred_bool))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 2-2-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model('./exp2-2-2', custom_objects={'LSTMCell': tf.keras.layers.LSTM})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "248/248 [==============================] - 506s 2s/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.23      0.01      0.02      1410\n",
      "           1       0.07      0.46      0.12       810\n",
      "           2       0.06      0.04      0.05      1110\n",
      "           3       0.06      0.03      0.04       510\n",
      "           4       0.13      0.28      0.17       495\n",
      "           5       0.11      0.05      0.07       660\n",
      "           6       0.00      0.00      0.00       510\n",
      "           7       0.17      0.00      0.00       660\n",
      "           8       0.04      0.01      0.01       960\n",
      "           9       0.35      0.02      0.04       810\n",
      "\n",
      "    accuracy                           0.08      7935\n",
      "   macro avg       0.12      0.09      0.05      7935\n",
      "weighted avg       0.13      0.08      0.05      7935\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "y_pred = model.predict(x, batch_size=32, verbose=1)\n",
    "y_pred_bool = np.argmax(y_pred, axis=1)\n",
    "\n",
    "print(classification_report(y, y_pred_bool))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 2-2-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model('./exp2-2-3', custom_objects={'LSTMCell': tf.keras.layers.LSTM})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "248/248 [==============================] - 494s 2s/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.23      0.50      0.31      1410\n",
      "           1       0.02      0.09      0.04       810\n",
      "           2       0.06      0.05      0.05      1110\n",
      "           3       0.05      0.03      0.04       510\n",
      "           4       0.29      0.08      0.13       495\n",
      "           5       0.00      0.00      0.00       660\n",
      "           6       0.00      0.00      0.00       510\n",
      "           7       0.05      0.01      0.02       660\n",
      "           8       0.00      0.00      0.00       960\n",
      "           9       0.00      0.00      0.00       810\n",
      "\n",
      "    accuracy                           0.11      7935\n",
      "   macro avg       0.07      0.08      0.06      7935\n",
      "weighted avg       0.08      0.11      0.08      7935\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ltw97\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\ltw97\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\ltw97\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "y_pred = model.predict(x, batch_size=32, verbose=1)\n",
    "y_pred_bool = np.argmax(y_pred, axis=1)\n",
    "\n",
    "print(classification_report(y, y_pred_bool))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
